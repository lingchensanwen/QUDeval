# QUDeval: Evaluating Questions Under Discussion Discourse Parsing

Welcome to the official repository for the EMNLP 2023 paper, "QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing."

**Authors:** [Yating Wu](http://lingchensanwen.github.io), [Ritika Mangla](https://ritikamangla01.netlify.app), [Greg Durrett](https://www.cs.utexas.edu/~gdurrett/), and [Junyi Jessy Li](https://jessyli.com)

## Introduction ğŸŒŸ

This work introduces the first framework for the automatic evaluation of QUD parsing, instantiating the theoretical constraints of QUD in a concrete protocol. 

## Table of Contents ğŸ“š

1. [Data Collection](#data-collection)
2. [Code for Evaluation](#code-for-evaluation)

## Data Collection ğŸ“¥

The data is placed under the [`data`](https://github.com/lingchensanwen/QUDeval/tree/main/data) folder.

## Code for Evaluation ğŸ–¥ï¸

*Work in progress:* We're in the process of finalizing the scripts for data processing and evaluation. These resources will soon be available in the [`code`](https://github.com/lingchensanwen/QUDeval/tree/main/code) folder.

---

Stay tuned for more updates, and thank you for your interest in QUDeval!

