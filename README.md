# QUDeval: Evaluating Questions Under Discussion Discourse Parsing

Welcome to the official repository for the EMNLP 2023 paper, "QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing."

**Authors:** [Yating Wu](http://lingchensanwen.github.io), [Ritika Mangla](https://ritikamangla01.netlify.app), [Greg Durrett](https://www.cs.utexas.edu/~gdurrett/), and [Junyi Jessy Li](https://jessyli.com)


If you find our work useful or relevant to your research, please consider citing our paper. 
```bibtex
@inproceedings{wu2023qudeval,
    title={QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing},
    author={Wu, Yating and Mangla, Ritika and Durrett, Greg and Li, Junyi Jessy},
    booktitle={EMNLP 2023},
    pages={to appear},
    year={2023}
}

```

## Introduction üåü

This work introduces the first framework for the automatic evaluation of QUD parsing, instantiating the theoretical constraints of QUD in a concrete protocol. 

## Table of Contents üìö

1. [Data Collection](#data-collection)
2. [Code for Evaluation](#code-for-evaluation)

## Data Collection üì•

The data is placed under the [`data`](https://github.com/lingchensanwen/QUDeval/tree/main/data) folder.

## Code for Evaluation üñ•Ô∏è

*Work in progress:* We're in the process of finalizing the scripts for data processing and evaluation. These resources will soon be available in the [`code`](https://github.com/lingchensanwen/QUDeval/tree/main/code) folder. You can check the progress under this path as well.

## UI for Collection üìÅ

The code can be found under [this repo](https://github.com/lingchensanwen/QUD-eval-data-collection-flask)
